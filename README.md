# awesome-embodied-ai-ros

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
<img src="https://img.shields.io/badge/Contributions-Welcome-278ea5" alt="Contrib"/>

A curated list of repositories and papers on Embodied AI in ROS ecosystem.

## Repositories

### Frameworks

- [rai](https://github.com/RobotecAI/rai) - a generic AI Agent framework for ROS 2.
- [ROSA](https://github.com/nasa-jpl/rosa) - to inspect, diagnose, understand, and operate robots.
- [ros4hri](https://github.com/ros4hri) - umbrella for all the ROS packages, conventions and tools that help developing interactive robots with ROS.
- [stretch_ai](https://github.com/hello-robot/stretch_ai) - designed to help researchers and developers build intelligent behaviors for the Stretch 3 mobile manipulator.

### Tools

- [ros_to_markdown](https://github.com/RobRoyce/ros_to_markdown) - convert ROS systems to Markdown for LLM processing.
- [git2md](https://github.com/xpos587/git2md) - tool for converting Git repository contents into Markdown format.

### User tools

- [ros2ai](https://github.com/fujitatomoya/ros2ai) - command line interface extension, especially for those learning ROS.

### Model integrations

- [llama_ros](https://github.com/mgonzs13/llama_ros) - integrated llama.cpp
- [whisper_ros](https://github.com/mgonzs13/whisper_ros) - listen to speech and generate responses.
- [yolo_ros](https://github.com/mgonzs13/yolo_ros) - ROS 2 wrap for YOLO models 
- [piper_ros](https://github.com/mgonzs13/piper_ros) - set of ROS 2 packages to integrate piper TTS (Text-to-Speech) 

### Inference & Training

- [mlc-llm](https://github.com/mlc-ai/mlc-llm) - Universal LLM Deployment Engine with ML Compilation
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - LLM inference in C/C++

### Projects

- [rai-agriculture-demo](https://github.com/RobotecAI/rai-agriculture-demo) + [rai docs link](https://github.com/RobotecAI/rai/blob/development/docs/demos/agriculture.md) - in a beautiful scene of a virtual orchard, RAI goes beyond obstacle detection to analyze best course of action for a given unexpected situation.
- [rai-manipulation-demo](https://github.com/RobotecAI/rai-manipulation-demo) + [rai docs link](https://github.com/RobotecAI/rai/blob/development/docs/demos/manipulation.md) - complete flexible manipulation tasks thanks to RAI and Grounded SAM 2 
- [rai-rosbot-xl-demo](https://github.com/RobotecAI/rai-rosbot-xl-demo) + [rai docs link](https://github.com/RobotecAI/rai/blob/development/docs/demos/rosbot_xl.md) - demonstrate RAI's interaction with an autonomous mobile robot platform for navigation and control
- [tabletop-handybot](https://github.com/ycheng517/tabletop-handybot) - AI-powered robot arm assistant.
- [chatbot_ros](https://github.com/mgonzs13/chatbot_ros) - combines `whisper_ros`,`llama_ros`, and `piper_ros`for conversational AI

### Stale repositories

- [turtlebot3_drlnav](https://github.com/tomasvr/turtlebot3_drlnav) - A ROS 2 framework for DRL autonomous navigation on mobile robots with LiDAR.

### Related `awesome-*` lists

- [awesome-foundation-model-ros](https://github.com/ycheng517/awesome-foundation-model-ros) - a collection of ROS projects and resources utilizing or simplifying the application of foundation models in robotics.

## Other EmbodiedAI Repositories

Interensting projects without `ROS` integration yet

### Vision-Language-Action Models & Projects

- [open-pi-zero](https://github.com/allenzren/open-pi-zero) - this repo implements the pi0 model from Physical Intelligence (Pi)

### World Foundation Models

- [Cosmos](https://github.com/NVIDIA/Cosmos) - developer-first world foundation model platform  designed to help developers build their Physical AI systems 

## Papers
